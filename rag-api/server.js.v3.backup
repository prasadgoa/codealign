require('dotenv').config();
const express = require('express');
const multer = require('multer');
const axios = require('axios');
const cors = require('cors');
const DocumentDatabase = require('./database');

const app = express();
const PORT = process.env.PORT || 3001;

// Configuration
const N8N_BASE_URL = 'http://35.209.113.236:5678';
const UPLOAD_WEBHOOK = `${N8N_BASE_URL}/webhook/upload-document`;
const QUERY_WEBHOOK = `${N8N_BASE_URL}/webhook/query-compliance`;

// Middleware
app.use(cors({
  origin: ['http://35.209.113.236:3000', 'http://localhost:3000'],
  credentials: true
}));
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// Configure multer for file uploads
const upload = multer({
  storage: multer.memoryStorage(),
  limits: {
    fileSize: 50 * 1024 * 1024, // 50MB limit
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = [
      'application/pdf',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'application/msword',
      'text/plain'
    ];
    
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('Invalid file type. Only PDF, DOCX, and TXT files are allowed.'));
    }
  }
});

// Health check endpoint
app.get('/health', async (req, res) => {
  const dbHealth = await DocumentDatabase.healthCheck();
  
  res.json({ 
    status: 'healthy', 
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    database: dbHealth
  });
});

// Internal endpoint for n8n to store chunk metadata
app.post('/api/internal/store-chunks', async (req, res) => {
  try {
    const { document_id, chunks } = req.body;
    
    if (!document_id || !chunks || !Array.isArray(chunks)) {
      return res.status(400).json({
        error: 'Missing document_id or chunks array',
        success: false
      });
    }

    console.log(`Storing ${chunks.length} chunks for document ${document_id}`);

    // Store chunks in database
    const storedCount = await DocumentDatabase.storeChunks(document_id, chunks);
    
    // Update document status to completed
    await DocumentDatabase.updateDocumentStatus(document_id, 'completed', chunks.length);
    
    // Log completion
    await DocumentDatabase.logProcessingStep(
      document_id, 
      'storage', 
      'completed', 
      `Stored ${storedCount} chunks in database and vector store`
    );

    res.json({
      success: true,
      message: 'Chunks stored successfully',
      document_id: document_id,
      stored_chunks: storedCount
    });

  } catch (error) {
    console.error('Store chunks error:', error);
    
    // Log failure if we have document_id
    if (req.body.document_id) {
      try {
        await DocumentDatabase.updateDocumentStatus(req.body.document_id, 'failed');
        await DocumentDatabase.logProcessingStep(
          req.body.document_id, 
          'storage', 
          'failed', 
          error.message
        );
      } catch (logError) {
        console.error('Failed to log error:', logError.message);
      }
    }

    res.status(500).json({
      error: 'Failed to store chunks',
      success: false
    });
  }
});

// Get all documents endpoint
app.get('/api/documents', async (req, res) => {
  try {
    const page = parseInt(req.query.page) || 1;
    const limit = parseInt(req.query.limit) || 20;
    const status = req.query.status || null;
    const offset = (page - 1) * limit;

    const documents = await DocumentDatabase.getDocuments(offset, limit, status);
    
    // Get total count for pagination
    const { Pool } = require('pg');
    const countPool = new Pool({
      host: process.env.DB_HOST || 'localhost',
      port: process.env.DB_PORT || 5433,
      database: process.env.DB_NAME || 'rag_system',
      user: process.env.DB_USER || 'rag_user',
      password: process.env.DB_PASSWORD || 'rag_secure_2025'
    });
    
    const countQuery = status 
      ? 'SELECT COUNT(*) FROM documents WHERE processing_status = $1'
      : 'SELECT COUNT(*) FROM documents';
    const countParams = status ? [status] : [];
    
    const countResult = await countPool.query(countQuery, countParams);
    const total = parseInt(countResult.rows[0].count);
    countPool.end();

    res.json({
      success: true,
      documents,
      pagination: {
        page,
        limit,
        total,
        pages: Math.ceil(total / limit)
      }
    });
  } catch (error) {
    console.error('Get documents error:', error);
    res.status(500).json({
      error: 'Failed to retrieve documents',
      success: false
    });
  }
});

// Get specific document with chunks
app.get('/api/documents/:id', async (req, res) => {
  try {
    const documentId = parseInt(req.params.id);
    const document = await DocumentDatabase.getDocumentById(documentId);
    
    if (!document) {
      return res.status(404).json({
        error: 'Document not found',
        success: false
      });
    }

    res.json({
      success: true,
      document
    });
  } catch (error) {
    console.error('Get document error:', error);
    res.status(500).json({
      error: 'Failed to retrieve document',
      success: false
    });
  }
});

// Delete specific document
app.delete('/api/documents/:id', async (req, res) => {
  try {
    const documentId = parseInt(req.params.id);
    const result = await DocumentDatabase.deleteDocument(documentId);
    
    if (!result.deletedDocument) {
      return res.status(404).json({
        error: 'Document not found',
        success: false
      });
    }

    // Delete vectors from Qdrant
    let deletedVectorCount = 0;
    if (result.vectorIds.length > 0) {
      try {
        const deletePromises = result.vectorIds.map(async (vectorId) => {
          try {
            await axios.delete(`http://172.17.0.1:6333/collections/compliance_docs/points/${vectorId}`);
            deletedVectorCount++;
          } catch (qdrantError) {
            console.warn(`Failed to delete vector ${vectorId}:`, qdrantError.message);
          }
        });
        await Promise.allSettled(deletePromises);
      } catch (error) {
        console.warn('Qdrant vector deletion warning:', error.message);
      }
    }

    res.json({
      success: true,
      message: 'Document and associated vectors deleted successfully',
      deletedDocument: result.deletedDocument,
      deletedVectors: deletedVectorCount
    });
  } catch (error) {
    console.error('Delete document error:', error);
    res.status(500).json({
      error: 'Failed to delete document',
      success: false
    });
  }
});

// Delete all documents
app.delete('/api/documents', async (req, res) => {
  try {
    const result = await DocumentDatabase.deleteAllDocuments();

    // Clear entire Qdrant collection
    try {
      await axios.delete('http://172.17.0.1:6333/collections/compliance_docs');
      // Recreate empty collection
      await axios.put('http://172.17.0.1:6333/collections/compliance_docs', {
        vectors: {
          size: 384,
          distance: "Cosine"
        }
      });
    } catch (qdrantError) {
      console.warn('Qdrant collection reset warning:', qdrantError.message);
    }

    res.json({
      success: true,
      message: 'All documents and vectors deleted successfully',
      deletedVectors: result.vectorIds.length
    });
  } catch (error) {
    console.error('Delete all documents error:', error);
    res.status(500).json({
      error: 'Failed to delete documents',
      success: false
    });
  }
});

// Document upload endpoint - enhanced with database integration
app.post('/api/upload-document', upload.single('file'), async (req, res) => {
  let documentRecord = null;
  
  try {
    console.log(`[${new Date().toISOString()}] Document upload request received`);
    
    if (!req.file) {
      return res.status(400).json({ 
        error: 'No file provided',
        success: false 
      });
    }

    console.log(`File details: ${req.file.originalname}, ${req.file.size} bytes, ${req.file.mimetype}`);

    // Generate file hash and check for duplicates
    const fileHash = DocumentDatabase.generateFileHash(req.file.buffer);
    const existingDoc = await DocumentDatabase.documentExists(fileHash);
    
    if (existingDoc) {
      return res.status(409).json({
        error: 'Document already exists',
        success: false,
        existingDocument: existingDoc
      });
    }

    // Create document record in database
    documentRecord = await DocumentDatabase.createDocument({
      filename: req.file.originalname,
      originalFilename: req.file.originalname,
      fileSize: req.file.size,
      mimeType: req.file.mimetype,
      fileHash: fileHash
    });

    // Log processing start
    await DocumentDatabase.logProcessingStep(documentRecord.id, 'upload', 'completed', 'File received and stored in database');

    // Create FormData for n8n webhook
    const FormData = require('form-data');
    const formData = new FormData();
    formData.append('file', req.file.buffer, {
      filename: req.file.originalname,
      contentType: req.file.mimetype
    });
    formData.append('document_id', documentRecord.id.toString());

    // Forward to n8n webhook
    const response = await axios.post(UPLOAD_WEBHOOK, formData, {
      headers: {
        ...formData.getHeaders(),
      },
      timeout: 120000,
      maxContentLength: 50 * 1024 * 1024,
      maxBodyLength: 50 * 1024 * 1024
    });

    console.log(`n8n response: ${response.status}`);
    
    res.json({
      success: true,
      message: 'Document uploaded and processing started',
      filename: req.file.originalname,
      documentId: documentRecord.id,
      data: response.data
    });

  } catch (error) {
    console.error('Upload error:', error.message);
    
    // Update document status to failed if record was created
    if (documentRecord) {
      try {
        await DocumentDatabase.updateDocumentStatus(documentRecord.id, 'failed');
        await DocumentDatabase.logProcessingStep(documentRecord.id, 'processing', 'failed', error.message);
      } catch (dbError) {
        console.error('Failed to update document status:', dbError.message);
      }
    }
    
    if (error.code === 'ECONNREFUSED') {
      return res.status(503).json({
        error: 'n8n service unavailable',
        success: false
      });
    }
    
    if (error.response) {
      return res.status(error.response.status).json({
        error: 'n8n processing failed',
        details: error.response.data,
        success: false
      });
    }

    res.status(500).json({
      error: 'Internal server error during upload',
      success: false
    });
  }
});

// Query endpoint
app.post('/api/query', async (req, res) => {
  try {
    console.log(`[${new Date().toISOString()}] Query request received`);
    
    const { query, filters } = req.body;
    
    if (!query || query.trim() === '') {
      return res.status(400).json({
        error: 'Query is required',
        success: false
      });
    }

    console.log(`Query: "${query}"`);

    const response = await axios.post(QUERY_WEBHOOK, {
      query: query.trim(),
      filters: filters || {}
    }, {
      timeout: 60000,
      headers: {
        'Content-Type': 'application/json'
      }
    });

    console.log(`n8n query response: ${response.status}`);
    
    let responseData;
    if (typeof response.data === 'string') {
      try {
        responseData = JSON.parse(response.data);
      } catch (parseError) {
        console.error('JSON parse error:', parseError.message);
        console.error('Error position:', parseError.message.match(/position (\d+)/)?.[1] || 'unknown');
        
        const errorPos = parseInt(parseError.message.match(/position (\d+)/)?.[1]) || 0;
        const start = Math.max(0, errorPos - 20);
        const end = Math.min(response.data.length, errorPos + 20);
        console.error('Problematic JSON segment:', response.data.substring(start, end));
        
        try {
          const questionMatch = response.data.match(/"question":\s*"([^"]*?)"/);
          const resultsMatch = response.data.match(/"results":\s*"([^"]*?)"/);
          const chunksMatch = response.data.match(/"found_chunks":\s*(\d+)/);
          
          if (questionMatch && resultsMatch && chunksMatch) {
            console.log('Using manual extraction fallback');
            responseData = {
              question: questionMatch[1],
              results: resultsMatch[1],
              found_chunks: parseInt(chunksMatch[1]),
              status: 'success'
            };
          } else {
            throw new Error('Manual extraction failed');
          }
        } catch (extractError) {
          console.error('Manual extraction also failed:', extractError.message);
          return res.status(500).json({
            error: 'Response parsing failed',
            success: false
          });
        }
      }
    } else {
      responseData = response.data;
    }

    res.json({
      success: true,
      query: query,
      answer: responseData.results || responseData.answer || "No answer generated",
      sources: responseData.sources || [],
      found_chunks: responseData.found_chunks || 0,
      status: responseData.status || 'success'
    });

  } catch (error) {
    console.error('Query error:', error.message);
    
    if (error.code === 'ECONNREFUSED') {
      return res.status(503).json({
        error: 'n8n service unavailable',
        success: false
      });
    }
    
    if (error.response) {
      return res.status(error.response.status).json({
        error: 'n8n query failed',
        details: error.response.data,
        success: false
      });
    }

    res.status(500).json({
      error: 'Internal server error during query',
      success: false
    });
  }
});

// Test n8n connectivity
app.get('/api/test-n8n', async (req, res) => {
  try {
    const uploadTest = axios.get(`${N8N_BASE_URL}/healthz`).catch(() => ({ status: 'error' }));
    const results = await Promise.allSettled([uploadTest]);
    
    res.json({
      n8n_health: results[0].status === 'fulfilled' ? 'healthy' : 'unhealthy',
      upload_webhook: UPLOAD_WEBHOOK,
      query_webhook: QUERY_WEBHOOK,
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      error: 'Failed to test n8n connectivity',
      details: error.message
    });
  }
});

// Error handling middleware
app.use((error, req, res, next) => {
  if (error instanceof multer.MulterError) {
    if (error.code === 'LIMIT_FILE_SIZE') {
      return res.status(400).json({
        error: 'File too large. Maximum size is 50MB.',
        success: false
      });
    }
  }
  
  console.error('Unhandled error:', error);
  res.status(500).json({
    error: 'Internal server error',
    success: false
  });
});

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('SIGTERM received, shutting down gracefully');
  process.exit(0);
});

process.on('SIGINT', () => {
  console.log('SIGINT received, shutting down gracefully');
  process.exit(0);
});

// Start server
app.listen(PORT, '0.0.0.0', () => {
  console.log(`=================================`);
  console.log(`🚀 RAG API Server running on port ${PORT}`);
  console.log(`📡 n8n webhooks: ${N8N_BASE_URL}`);
  console.log(`💾 Database: ${process.env.DB_NAME}@${process.env.DB_HOST}:${process.env.DB_PORT}`);
  console.log(`🔗 Health check: http://35.209.113.236:${PORT}/health`);
  console.log(`=================================`);
});

module.exports = app;
